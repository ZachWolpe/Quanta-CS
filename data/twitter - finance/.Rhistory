ggplot(dataset, aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
geom_line(aes(x=Date, y=dur), col='darkgreen', alpha=0.3) +
geom_line(aes(x=Date, y=blm), col='black', alpha=0.3) +
geom_line(aes(x=Date, y=pta), col='lightblue', alpha=0.3) +
ggtitle("Regular Temperature")
# correlation in temperature
dataset.corr = cor(dataset[,2:ncol(dataset)])
# plot correlation
library(corrplot)
corrplot(dataset.corr)
```{}
jhb
```
```{}
jhb
```
jhb
jhb
install.packages("reticulate")
library(reticulate)
jhb
library(reticulate)
```{r}
```{r}
jhb
cloudcover
jhb$cloudcover
jhb
# set working directory
setwd("~/Desktop/Quanta_CS/analysis")
# import weather data
jhb = read.csv("../data/weather/johannesburg.csv")
ct = read.csv("../data/weather/capetown.csv")
dur = read.csv("../data/weather/durban.csv")
pta = read.csv("../data/weather/pretoria.csv")
blm = read.csv("../data/weather/Bloemfontein.csv")
# JSE data
jse = read.csv('../data/jse/JALSH.csv')
jse
jhb
ct
library(tidyverse)
library(dplyr)
library(ggplot2)
# clean data
jse$Price = as.numeric(gsub(",", "",jse$Price))
jse$Open = as.numeric(gsub(",", "",jse$Open))
jse$Low = as.numeric(gsub(",", "",jse$Low))
jse$High = as.numeric(gsub(",", "",jse$High))
# Volume
jse$Vol. = gsub("M", "000000", jse$Vol.)
jse$Vol. = gsub("B", "000000000", jse$Vol.)
jse$Vol. = as.numeric(jse$Vol.)
jse$Vol.[which(jse$Vol. < 10)] = jse$Vol.[jse$Vol. < 10]*10000
# Date
jse$Date = as.Date(jse$Date, format="%b %d, %Y")
# Keep: date, price & vol
jse = jse %>% select('Date', "Price", "Vol.")
jse
# View Cleanup
head(jse)
# standardized price
jse$z_price = (jse$Price - mean(jse$Price))/sd(jse$Price)
# plot
jse_plot <- ggplot(jse, aes(x=Date, y=Price)) + geom_line(col='darkblue') + ggtitle("JSE All Shares Index")
jse_plot_z <- ggplot(jse, aes(x=Date, y=z_price)) + geom_line(col='maroon') + ggtitle("JSE All Shares Index Standardized")
jse_plot
jse_plot_z
library(dplyr)
library(docstring)
# Clean Date
jhb$Date = as.Date(jhb$date_time)
ct$Date = as.Date(ct$date_time)
dur$Date = as.Date(dur$date_time)
pta$Date = as.Date(pta$date_time)
blm$Date = as.Date(blm$date_time)
standard_mean_temp <- function(dataset) {
" Return standardized temoerature - attached to dataframe "
daily_mean <- dataset %>% group_by(Date) %>% summarise(mean = mean(tempC))
mean_z <- (daily_mean$mean - mean(daily_mean$mean))/sd(daily_mean$mean)
}
# compute std_z temperature
jhb$temp_z = standard_mean_temp(jhb)
ct$temp_z = standard_mean_temp(ct)
dur$temp_z = standard_mean_temp(dur)
blm$temp_z = standard_mean_temp(blm)
pta$temp_z = standard_mean_temp(pta)
# create 1 dateset with temperatures
dataset = cbind(jhb$Date, jhb$temp_z,ct$temp_z, dur$temp_z, blm$temp_z, pta$temp_z)
colnames(dataset) = c("Date", 'jhb', 'ct', 'dur', 'blm', 'pta')
dataset = data.frame(dataset)
library(ggplot2)
ggplot(dataset, aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
geom_line(aes(x=Date, y=dur), col='darkgreen', alpha=0.3) +
geom_line(aes(x=Date, y=blm), col='black', alpha=0.3) +
geom_line(aes(x=Date, y=pta), col='lightblue', alpha=0.3) +
ggtitle("Regular Temperature")
# correlation in temperature
dataset.corr = cor(dataset[,2:ncol(dataset)])
# plot correlation
library(corrplot)
corrplot(dataset.corr)
min(jse$Date)
min(jse$Date), max(jse$Date)
min(jse$Date)
max(jse$Date)
max(jse$Date)
min(jse$Date)
min(jhb$Date)
max(jhb$Date)
# set working directory
setwd("~/Desktop/Quanta_CS/analysis")
# import weather data
jhb = read.csv("../data/weather/johannesburg.csv")
ct = read.csv("../data/weather/capetown.csv")
dur = read.csv("../data/weather/durban.csv")
pta = read.csv("../data/weather/pretoria.csv")
blm = read.csv("../data/weather/Bloemfontein.csv")
# JSE data
jse = read.csv('../data/jse/JALSH.csv')
jhb
nrow(jhb)/8
norw(jse)
nrow(jse)
nrow(jhb)/8
# set working directory
setwd("~/Desktop/Quanta_CS/analysis")
# import weather data
jhb = read.csv("../data/weather/johannesburg.csv")
ct = read.csv("../data/weather/capetown.csv")
dur = read.csv("../data/weather/durban.csv")
pta = read.csv("../data/weather/pretoria.csv")
blm = read.csv("../data/weather/Bloemfontein.csv")
# JSE data
jse = read.csv('../data/jse/JALSH.csv')
nrow(blm)
nrow(jhb)
# View Cleanup
head(jse)
# standardized price
jse$z_price = (jse$Price - mean(jse$Price))/sd(jse$Price)
# View Cleanup
head(jse)
# standardized price
jse$z_price = (jse$Price - mean(jse$Price))/sd(jse$Price)
library(tidyverse)
library(dplyr)
library(ggplot2)
# clean data
jse$Price = as.numeric(gsub(",", "",jse$Price))
jse$Open = as.numeric(gsub(",", "",jse$Open))
jse$Low = as.numeric(gsub(",", "",jse$Low))
jse$High = as.numeric(gsub(",", "",jse$High))
# Volume
jse$Vol. = gsub("M", "000000", jse$Vol.)
jse$Vol. = gsub("B", "000000000", jse$Vol.)
jse$Vol. = as.numeric(jse$Vol.)
jse$Vol.[which(jse$Vol. < 10)] = jse$Vol.[jse$Vol. < 10]*10000
# Date
jse$Date = as.Date(jse$Date, format="%b %d, %Y")
# Keep: date, price & vol
jse = jse %>% select('Date', "Price", "Vol.")
# View Cleanup
head(jse)
# standardized price
jse$z_price = (jse$Price - mean(jse$Price))/sd(jse$Price)
# plot
jse_plot <- ggplot(jse, aes(x=Date, y=Price)) + geom_line(col='darkblue') + ggtitle("JSE All Shares Index")
jse_plot_z <- ggplot(jse, aes(x=Date, y=z_price)) + geom_line(col='maroon') + ggtitle("JSE All Shares Index Standardized")
jse_plot
jse_plot_z
library(dplyr)
library(docstring)
# Clean Date
jhb$Date = as.Date(jhb$date_time)
ct$Date = as.Date(ct$date_time)
dur$Date = as.Date(dur$date_time)
pta$Date = as.Date(pta$date_time)
blm$Date = as.Date(blm$date_time)
standard_mean_temp <- function(dataset) {
" Return standardized temoerature - attached to dataframe "
daily_mean <- dataset %>% group_by(Date) %>% summarise(mean = mean(tempC))
mean_z <- (daily_mean$mean - mean(daily_mean$mean))/sd(daily_mean$mean)
}
# compute std_z temperature
jhb$temp_z = standard_mean_temp(jhb)
ct$temp_z = standard_mean_temp(ct)
dur$temp_z = standard_mean_temp(dur)
blm$temp_z = standard_mean_temp(blm)
pta$temp_z = standard_mean_temp(pta)
# create 1 dateset with temperatures
dataset = cbind(jhb$Date, jhb$temp_z,ct$temp_z, dur$temp_z, blm$temp_z, pta$temp_z)
colnames(dataset) = c("Date", 'jhb', 'ct', 'dur', 'blm', 'pta')
dataset = data.frame(dataset)
library(ggplot2)
ggplot(dataset, aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
geom_line(aes(x=Date, y=dur), col='darkgreen', alpha=0.3) +
geom_line(aes(x=Date, y=blm), col='black', alpha=0.3) +
geom_line(aes(x=Date, y=pta), col='lightblue', alpha=0.3) +
ggtitle("Regular Temperature")
# correlation in temperature
dataset.corr = cor(dataset[,2:ncol(dataset)])
# plot correlation
library(corrplot)
corrplot(dataset.corr)
jhb
# set working directory
setwd("~/Desktop/Quanta_CS/analysis")
# import weather data
jhb = read.csv("../data/weather/johannesburg.csv")
ct = read.csv("../data/weather/capetown.csv")
dur = read.csv("../data/weather/durban.csv")
pta = read.csv("../data/weather/pretoria.csv")
blm = read.csv("../data/weather/Bloemfontein.csv")
# JSE data
jse = read.csv('../data/jse/JALSH.csv')
library(tidyverse)
library(dplyr)
library(ggplot2)
# clean data
jse$Price = as.numeric(gsub(",", "",jse$Price))
jse$Open = as.numeric(gsub(",", "",jse$Open))
jse$Low = as.numeric(gsub(",", "",jse$Low))
jse$High = as.numeric(gsub(",", "",jse$High))
# Volume
jse$Vol. = gsub("M", "000000", jse$Vol.)
jse$Vol. = gsub("B", "000000000", jse$Vol.)
jse$Vol. = as.numeric(jse$Vol.)
jse$Vol.[which(jse$Vol. < 10)] = jse$Vol.[jse$Vol. < 10]*10000
# Date
jse$Date = as.Date(jse$Date, format="%b %d, %Y")
# Keep: date, price & vol
jse = jse %>% select('Date', "Price", "Vol.")
# View Cleanup
head(jse)
# standardized price
jse$z_price = (jse$Price - mean(jse$Price))/sd(jse$Price)
# plot
jse_plot <- ggplot(jse, aes(x=Date, y=Price)) + geom_line(col='darkblue') + ggtitle("JSE All Shares Index")
jse_plot_z <- ggplot(jse, aes(x=Date, y=z_price)) + geom_line(col='maroon') + ggtitle("JSE All Shares Index Standardized")
jse_plot
jse_plot_z
library(dplyr)
library(docstring)
# Clean Date
jhb$Date = as.Date(jhb$date_time)
ct$Date = as.Date(ct$date_time)
dur$Date = as.Date(dur$date_time)
pta$Date = as.Date(pta$date_time)
blm$Date = as.Date(blm$date_time)
standard_mean_temp <- function(dataset) {
" Return standardized temoerature - attached to dataframe "
daily_mean <- dataset %>% group_by(Date) %>% summarise(mean = mean(tempC))
mean_z <- (daily_mean$mean - mean(daily_mean$mean))/sd(daily_mean$mean)
}
# compute std_z temperature
jhb$temp_z = standard_mean_temp(jhb)
ct$temp_z = standard_mean_temp(ct)
dur$temp_z = standard_mean_temp(dur)
blm$temp_z = standard_mean_temp(blm)
pta$temp_z = standard_mean_temp(pta)
# create 1 dateset with temperatures
dataset = cbind(jhb$Date, jhb$temp_z,ct$temp_z, dur$temp_z, blm$temp_z, pta$temp_z)
colnames(dataset) = c("Date", 'jhb', 'ct', 'dur', 'blm', 'pta')
dataset = data.frame(dataset)
library(ggplot2)
ggplot(dataset, aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
geom_line(aes(x=Date, y=dur), col='darkgreen', alpha=0.3) +
geom_line(aes(x=Date, y=blm), col='black', alpha=0.3) +
geom_line(aes(x=Date, y=pta), col='lightblue', alpha=0.3) +
ggtitle("Regular Temperature")
# correlation in temperature
dataset.corr = cor(dataset[,2:ncol(dataset)])
# plot correlation
library(corrplot)
corrplot(dataset.corr)
ggplot(dataset, aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
ggtitle("Regular Temperature")
ggplot((dataset[1:100,]), aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
ggtitle("Regular Temperature")
ggplot((dataset[1:1000,]), aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
ggtitle("Regular Temperature")
ggplot((dataset[1:10000,]), aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
ggtitle("Regular Temperature")
ggplot((dataset[1:5000,]), aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
ggtitle("Regular Temperature")
ggplot((dataset[1:2000,]), aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
ggtitle("Regular Temperature")
ggplot(dataset, aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
geom_line(aes(x=Date, y=dur), col='darkgreen', alpha=0.3) +
geom_line(aes(x=Date, y=blm), col='black', alpha=0.3) +
geom_line(aes(x=Date, y=pta), col='lightblue', alpha=0.3) +
ggtitle("Regular Temperature")
install.packages("twitteR")
library("twitterR")
library("twitteR")
install.packages("twitteR")
install.packages("twitteR")
library("twitteR")
?twitteR
??twitteR
??twitteR
??twitteR
ggplot(dataset[1:100,], aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
geom_line(aes(x=Date, y=dur), col='darkgreen', alpha=0.3) +
geom_line(aes(x=Date, y=blm), col='black', alpha=0.3) +
geom_line(aes(x=Date, y=pta), col='lightblue', alpha=0.3) +
ggtitle("Regular Temperature")
library(dplyr)
library(docstring)
# Clean Date
jhb$Date = as.Date(jhb$date_time)
ct$Date = as.Date(ct$date_time)
dur$Date = as.Date(dur$date_time)
pta$Date = as.Date(pta$date_time)
blm$Date = as.Date(blm$date_time)
standard_mean_temp <- function(dataset) {
" Return standardized temoerature - attached to dataframe "
daily_mean <- dataset %>% group_by(Date) %>% summarise(mean = mean(tempC))
mean_z <- (daily_mean$mean - mean(daily_mean$mean))/sd(daily_mean$mean)
}
# compute std_z temperature
jhb$temp_z = standard_mean_temp(jhb)
ct$temp_z = standard_mean_temp(ct)
dur$temp_z = standard_mean_temp(dur)
blm$temp_z = standard_mean_temp(blm)
pta$temp_z = standard_mean_temp(pta)
# create 1 dateset with temperatures
dataset = cbind(jhb$Date, jhb$temp_z,ct$temp_z, dur$temp_z, blm$temp_z, pta$temp_z)
colnames(dataset) = c("Date", 'jhb', 'ct', 'dur', 'blm', 'pta')
dataset = data.frame(dataset)
library(ggplot2)
ggplot(dataset[1:100,], aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
geom_line(aes(x=Date, y=dur), col='darkgreen', alpha=0.3) +
geom_line(aes(x=Date, y=blm), col='black', alpha=0.3) +
geom_line(aes(x=Date, y=pta), col='lightblue', alpha=0.3) +
ggtitle("Regular Temperature")
# correlation in temperature
dataset.corr = cor(dataset[,2:ncol(dataset)])
# plot correlation
library(corrplot)
corrplot(dataset.corr)
library(dplyr)
library(docstring)
# Clean Date
jhb$Date = as.Date(jhb$date_time)
ct$Date = as.Date(ct$date_time)
dur$Date = as.Date(dur$date_time)
pta$Date = as.Date(pta$date_time)
blm$Date = as.Date(blm$date_time)
standard_mean_temp <- function(dataset) {
" Return standardized temoerature - attached to dataframe "
daily_mean <- dataset %>% group_by(Date) %>% summarise(mean = mean(tempC))
mean_z <- (daily_mean$mean - mean(daily_mean$mean))/sd(daily_mean$mean)
}
# compute std_z temperature
jhb$temp_z = standard_mean_temp(jhb)
ct$temp_z = standard_mean_temp(ct)
dur$temp_z = standard_mean_temp(dur)
blm$temp_z = standard_mean_temp(blm)
pta$temp_z = standard_mean_temp(pta)
# create 1 dateset with temperatures
dataset = cbind(jhb$Date, jhb$temp_z,ct$temp_z, dur$temp_z, blm$temp_z, pta$temp_z)
colnames(dataset) = c("Date", 'jhb', 'ct', 'dur', 'blm', 'pta')
dataset = data.frame(dataset)
library(ggplot2)
ggplot(dataset[1:2000,], aes(x=Date, y=jhb)) + geom_line(col='red',alpha=0.3) +
geom_line(aes(x=Date, y=ct), col='blue', alpha=0.3) +
geom_line(aes(x=Date, y=dur), col='darkgreen', alpha=0.3) +
geom_line(aes(x=Date, y=blm), col='black', alpha=0.3) +
geom_line(aes(x=Date, y=pta), col='lightblue', alpha=0.3) +
ggtitle("Regular Temperature")
# correlation in temperature
dataset.corr = cor(dataset[,2:ncol(dataset)])
# plot correlation
library(corrplot)
corrplot(dataset.corr)
## install rtweet from CRAN
install.packages("rtweet")
## load rtweet package
library(rtweet)
get_trends("san francisco")
search_users("#rstats", n = 1000)
tweet = search_users("#rstats", n = 1)
tweet
tweet['text']
tweet = search_users("#math", n = 1)
tweet['text']
get_trends("south africa", n=10)
get_trends("south africa")
get_timelines(c("cnn", "BBCWorld", "foxnews"), n = 3200)
tweet = get_timelines(c("cnn", "BBCWorld", "foxnews"), n = 3200)
tweet = get_timelines(c("cnn", "BBCWorld", "foxnews"), n = 3200)
tweet
tweet['created_at']
max(tweet['created_at'])
as.Date(tweet['created_at'])
as.Date(tweet['created_at'][1])
class(tweet['created_at'])
class(tweet['created_at'][0])
class(tweet['created_at'][1])
View(tweet)
head(tweet)
library(rtweet)
get_trends("south africa")
tweet = get_trends("south africa")
tweet = get_trends("south africa")
tweet[1]
?rtweet
getwd()
getwd()
install.packages("rjson")
library(rjson)
fromJSON("../../data/twitter - finance/JSE.json")
fromJSON("../../data/twitter\ -\ finance/JSE.json")
setwd("~/Desktop/Quanta_CS/data/twitter - finance")
setwd("~/Desktop/Quanta_CS/data/twitter - finance")
setwd("~/Desktop/Quanta_CS/data/twitter - finance")
fromJSON("JSE.json")
fromJSON("JSE.json")
fromJSON("JSE.json")
fromJSON(JSE.json)
fromJSON(file='JSE.json')
library(rjson)
fromJSON(file='JSE.json')
setwd("~/Desktop/Quanta_CS/data/twitter - finance")
fromJSON(file='JSE.json')
fromJSON(file='JSE.json')
as.data.frame()
as.data.frame
fromJSON('JSE.json')
fromJSON(file'JSE.json')
fromJSON(file='JSE.json')
fromJSON(file='AdrianSaville')
fromJSON(file='AdrianSaville.json')
fromJSON('AdrianSaville.json')
library(jsonlite)
fromJSON('AdrianSaville.json')
library(jsonlite)
fromJSON('AdrianSaville.json')
fromJSON('JSE.josn')
fromJSON('JSE.json')
fromJSON(file('JSE.json'))
stream_in(file("JSE.json"))
?fromJSON('JSE.json')
library(rjson)
fromJSON('JSE.json')
read_json('JSE.json')
read_json('JSE.json')
read_json('JSE.json', simplifyVector = TRUE)
fromJSON('JSE.json')
getwd()
setwd("~/Desktop/Quanta_CS/data/twitter - finance")
fromJSON('.JSE.json')
fromJSON('../../data/twitter - finance/JSE.json')
# Import Data
getwd()
library(rjson)
tweets.jse = fromJSON('../../data/twitter - finance/JSE.json')
tweets.adrian = fromJSON('../../data/twitter - finance/AdrianSaville.json')
tweets.finCrisis = fromJSON('../../data/twitter - finance/FinCrisis.json')
tweets.finPros = fromJSON('../../data/twitter - finance/FinProsperity.json')
tweets.Karin = fromJSON('../../data/twitter - finance/KarinRichards.json')
tweets.LStweets = fromJSON('../../data/twitter - finance/LStweets.json')
tweets.malema = fromJSON('../../data/twitter - finance/Malema.json')
tweets.NerinaVisser = fromJSON('../../data/twitter - finance/NerinaVisser.json')
tweets.PaulTheron = fromJSON('../../data/twitter - finance/PaulTheron.json')
tweets.Presidency = fromJSON('../../data/twitter - finance/Presidency.json')
tweets.recessionJHB = fromJSON('../../data/twitter - finance/recessionJHB_tweets.json')
tweets.TradersCorner = fromJSON('../../data/twitter - finance/TradersCorner.json')
tweets.warreningram = fromJSON('../../data/twitter - finance/warreningram.json')
tweets.WealthDist = fromJSON('../../data/twitter - finance/WealthDist.json')
tweets.jse
names(tweets.jse)
head(tweets.jse)
tweets.jse[['is_replied','is_reply_to','likes',"parent_tweet_id", "replies", "retweets","text",
'time_stamp']]
head(tweets.jse)
library(dplyr)
select(tweets.jse[['is_replied','is_reply_to','likes',"parent_tweet_id", "replies", "retweets","text",
'time_stamp']])
select(tweets.jse, c('is_replied','is_reply_to','likes',"parent_tweet_id", "replies", "retweets","text",
'time_stamp'))
head(tweets.jse)
select(tweets.jse, c('is_replied','is_reply_to','likes',"parent_tweet_id", "replies", "retweets","text",
'timestamp'))
tweets[1]
clean_data <- function(dataset) {
"Process each Twitter file"
#
select(tweets.jse, c('is_replied','is_reply_to','likes',"parent_tweet_id",
"replies", "retweets","text", 'timestamp'))
}
head(tweets.jse)
tweets.jse = select(tweets.jse, c('is_replied','is_reply_to','likes',"parent_tweet_id",
"replies", "retweets","text", 'timestamp'))
head(tweets.jse)
names(tweets.jse)
head(tweets.jse)
