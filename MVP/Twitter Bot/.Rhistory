library(tidytext)
library(tidyverse)
library(ggplot2)
library(sys)
library(lubridate)
library(randomcoloR)
names(dm$events$message_create)
dm <- direct_messages(token=twitter_token)
library(rtweet)
library(dplyr)
library(tidytext)
library(tidyverse)
library(ggplot2)
library(sys)
library(lubridate)
library(randomcoloR)
appname <- "QuantaLabsSentiment"                                         ## name assigned to created app
key <- "szmabseQ9HceMuv0xFQjveaRq"                                       ## api key
secret <- "6gKES04Mrx3nhNdSbmPTtwkRW20yLmmyl1fgfpzFHeWW8pfZ5t"           ## api secret
token <- "1208662769438003201-C5Od4DcVEKC3YKH8x4Tm398yaqpZFi"            ## api access token
token_secret <- "mj81VVg04Tem352M2KzTybXGV3FQRRVGYTsy95rA39geR"          ## api access token secret
twitter_token <- create_token(
app=appname,
consumer_key=key,
consumer_secret=secret,
access_token=token,
access_secret=token_secret)
# ________________________________________________ Communicate with User: DM ________________________________________________
screen_name <- 'ZachColinWolpe'
dm <- direct_messages(token=twitter_token)
names(dm$events$message_create)
dm$events[1,]
dm$[1,]
dm[1,]
dm
View(dm)
library(stringr)
stringr::str_detect("Quantbot please compute my Sentiment!", "please compute my sentiment")
stringr::str_detect("Quantbot please compute my sentiment!", "please compute my sentiment")
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
bananas <- c("banana", "Banana", "BANANA")
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
dm
dm$events$message_create
for (i in (1:nrow(dm$events$message_create))) {
print(i)
}
for (i in dm$events$message_create) {
print(i)
}
for (i in dm$events$message_create) {
print(i)
break
}
for (i in dm$events$message_create) {
print(i)
}
dm <- dm$events$message_create
for (i in (1:nrow(dm))) {
if (condition) {
}
}
for (i in (1:nrow(dm))) {
if (dm$recipient_id == 1208662769438003201) {
print(dm$text)
}
}
dm <- dm$events$message_create
for (i in (1:nrow(dm))) {
if (dm$recipient_id == 1208662769438003201) {
print(dm$text)
}
}
# ________________________________________________ Communicate with User: DM ________________________________________________
screen_name <- 'ZachColinWolpe'
dm <- direct_messages(token=twitter_token)
names(dm$events$message_create)
dm <- dm$events$message_create
for (i in (1:nrow(dm))) {
if (dm$recipient_id == 1208662769438003201) {
print(dm$text)
}
}
# ________________________________________________ Communicate with User: DM ________________________________________________
screen_name <- 'ZachColinWolpe'
dm <- direct_messages(token=twitter_token)
dm_select <- dm$events$message_create
dm_select
dm_select$target$recipient_id
for (i in (1:nrow(dm_select))) {
if (dm_select$target$recipient_id == '1208662769438003201') {
print(dm_select$text)
}
}
dm_select$message_data$text
for (i in (1:nrow(dm_select))) {
if (dm_select$target$recipient_id == '1208662769438003201') {
print(dm_select$message_data$text)
}
}
dm_select$message_data$text
for (i in (1:nrow(dm_select))) {
if (dm_select$target$recipient_id == '1208662769438003201') {
print(dm_select$message_data$text)
}
}
dm[['events']]
dm['events']
dm['events']['message_create']
dm['events']
dm$events
dm$events$message_create
dm$events$message_create$message_data.text
dm$events$message_create$message_data$text
dm$events$message_create$message_data$text
dm$events$message_create$message_data$text[1]
dm$events$message_create$message_data$text[2]
dm$events$message_create$target$recipient_id
# list of messages
dm$events$message_create$message_data$text
# list of recipient ID's
dm$events$message_create$target$recipient_id
dm$events
dim(dm$events)
dm$events[1,]
dm$events
# for each row in
dm$events$message_create %>% group_by(sender_id)
# for each row in
(dm$events$message_create %>% group_by(sender_id))[1,]
# for each row in
(dm$events$message_create %>% group_by(sender_id))[2,]
dm <- direct_messages(token=twitter_token)
names(dm$events$message_create)
# list of messages
dm$events$message_create$message_data$text
# ________________________________________________ Communicate with User: DM ________________________________________________
screen_name <- 'ZachColinWolpe'
dm <- direct_messages(token=twitter_token)
names(dm$events$message_create)
# list of messages
dm$events$message_create$message_data$text
# list of messages
dm$events$message_create$message_data$text
# list of recipient ID's
dm$events$message_create$target$recipient_id
# for each row in
(dm$events$message_create %>% group_by(sender_id))[2,]
# for each row in
(dm$events$message_create %>% group_by(sender_id))
# ________________________________________________ Communicate with User: DM ________________________________________________
screen_name <- 'ZachColinWolpe'
dm <- direct_messages(token=twitter_token)
# list of messages
dm$events$message_create$message_data$text
# list of messages
dm$events$message_create$message_data$text
appname <- "QuantaLabsSentiment"                                         ## name assigned to created app
key <- "szmabseQ9HceMuv0xFQjveaRq"                                       ## api key
secret <- "6gKES04Mrx3nhNdSbmPTtwkRW20yLmmyl1fgfpzFHeWW8pfZ5t"           ## api secret
token <- "1208662769438003201-C5Od4DcVEKC3YKH8x4Tm398yaqpZFi"            ## api access token
token_secret <- "mj81VVg04Tem352M2KzTybXGV3FQRRVGYTsy95rA39geR"          ## api access token secret
twitter_token <- create_token(
app=appname,
consumer_key=key,
consumer_secret=secret,
access_token=token,
access_secret=token_secret)
# ________________________________________________ Communicate with User: DM ________________________________________________
screen_name <- 'ZachColinWolpe'
dm <- direct_messages(token=twitter_token)
names(dm$events$message_create)
# list of messages
dm$events$message_create$message_data$text
# for each row in
(dm$events$message_create %>% group_by(sender_id))
# detect request
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
# detect request
stringr::str_detect((dm$events$message_create %>% group_by(sender_id)), regex("please compute my sentiment", ignore_case=TRUE))
# for each row in
(dm$events$message_create %>% group_by(sender_id))
# for each row in
(dm$events$message_create %>% group_by(sender_id))
# detect request
stringr::str_detect((dm$events$message_create %>% group_by(sender_id)) %>% select(message_data$text), regex("please compute my sentiment", ignore_case=TRUE))
# detect request
stringr::str_detect("Quantbot Please Compute My Sentiment!", regex("please compute my sentiment", ignore_case=TRUE))
# for each row in
(dm$events$message_create %>% group_by(sender_id))  %>% select(message_data$text)
# for each row in
(dm$events$message_create %>% group_by(sender_id)) %>% select(message_data)
# for each row in
(dm$events$message_create %>% group_by(sender_id)) %>% select(message_data,text)
# for each row in
(dm$events$message_create %>% group_by(sender_id)) %>% select(message_data)
# for each row in
(dm$events$message_create %>% group_by(sender_id)) %>% select(message_data$text)
# for each row in
((dm$events$message_create %>% group_by(sender_id)) %>% select(message_data) )$text
# for each row in
(dm$events$message_create %>% group_by(sender_id)) %>% select(message_data)
# for each row in
(dm$events$message_create %>% group_by(sender_id))
# for each row in
dm$events$message_create %>% group_by(sender_id)
# for each row in
(dm$events$message_create %>% group_by(sender_id))[1,]
# for each row in
(dm$events$message_create %>% group_by(sender_id))[2,]
# for each row in
(dm$events$message_create %>% group_by(sender_id))[3,]
# for each row in
dm$events$message_create
# for each row in
dim(dm$events$message_create )
dm$events$message_create$sender_id
unique(dm$events$message_create$sender_id)
# unique senders
unique_senders <- unique(dm$events$message_create$sender_id)
for (i in (1:length(unique_senders))) {
print(unique_senders[i])
}
# _____ Once we Have a Message _____
dm$events$message_create$sender_id
# _____ Once we Have a Message _____
dm$events$message_create
# _____ Once we Have a Message _____
dm$events$message_create[1,]
# _____ Once we Have a Message _____
dm$events$message_create[2,]
# _____ Once we Have a Message _____
dm$events$message_create[2,]$sender_id
# _____ Once we Have a Message _____
dm$events$message_create[2,]$message_data$text
str_detect(dm$events$message_create[2,]$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE))
dm$events$message_create[2,]$message_data$text
dm$events$message_create[2,]$sender_id
get_timeline(dm$events$message_create[2,]$sender_id)
print(get_timeline(dm$events$message_create[2,]$sender_id))
dm$events$message_create$message_data$text
str_detect(dm$events$message_create[2,]$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE))
str_detect(dm$events$message_create$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE))
str_detect(dm$events$message_create$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE)) && TRUE
str_detect(dm$events$message_create$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE)) & TRUE
dm$events
dim(dm$events)
dim(dm$events)[1]
(str_detect(dm$events$message_create[i,]$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE)))
for (i in (1:dim(dm$events)[1])) {
# for Each Row (Message)
if (str_detect(dm$events$message_create[i,]$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE))) {
#  user_id <- dm$events$message_create[2,]$sender_id
print(i)
}
}
for (i in (1:dim(dm$events)[1])) {
# for Each Row (Message)
if (str_detect(dm$events$message_create[i,]$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE))) {
#  user_id <- dm$events$message_create[2,]$sender_id
print(dm$events$message_create[i,]$sender_id)
}
}
# for each row (message)
for (i in (1:dim(dm$events)[1])) {
# check if message contains string
if (str_detect(dm$events$message_create[i,]$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE))) {
# set user ID
user_id <- dm$events$message_create[i,]$sender_id
print(dm$events$message_create[i,]$sender_id)
# check if user has already been accounted for
}
}
user_id
# check if user has already been accounted for
user_id
dm$events$message_create[i,]$sender_id
dm$events$message_create[2,]$sender_id
user_id
dm$events$message_create
dm$events$message_create$recipient_id
# check if user has already been accounted for (send reply after posted users)
dm$events$message_create$recipient_id
# check if user has already been accounted for (send reply after posted users)
dm$events$message_create$target$recipient_id
user_id
dm$events$message_create$target$recipient_id == user_id
dm$events$message_create[dm$events$message_create$target$recipient_id == user_id]
dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id]
dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id]
dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id]
str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
regex("Done! Check my Feed!", ignore_case=TRUE))
!str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
regex("Done! Check my Feed!", ignore_case=TRUE))
!str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
regex("Done! Check my Feed!", ignore_case=TRUE))
!str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
regex("Done! Check my Feed!", ignore_case=TRUE))
# for each row (message)
for (i in (1:dim(dm$events)[1])) {
# for each row (message)
for (i in (1:dim(dm$events)[1])) {
# for each row (message)
for (i in (1:dim(dm$events)[1])) {
# check if message contains string
if (str_detect(dm$events$message_create[i,]$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE))) {
# set user ID
user_id <- dm$events$message_create[i,]$sender_id
print(dm$events$message_create[i,]$sender_id)
# check if user has NOT already been accounted for (send reply after posted users)
if (!str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
regex("Done! Check my Feed!", ignore_case=TRUE))) {
print(dm$events$message_create[i,]$sender_id)
}
user_id
}
}
# for each row (message)
for (i in (1:dim(dm$events)[1])) {
# check if message contains string
if (str_detect(dm$events$message_create[i,]$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE))) {
# set user ID
user_id <- dm$events$message_create[i,]$sender_id
print(dm$events$message_create[i,]$sender_id)
# check if user has NOT already been accounted for (send reply after posted users)
if (!str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
regex("Done! Check my Feed!", ignore_case=TRUE))) {
print(dm$events$message_create[i,]$sender_id)
}
user_id
}
}
dim(dm$events)[1]
for (i in (1:dim(dm$events)[1])) {
# check if message contains string
if (str_detect(dm$events$message_create[i,]$message_data$text,
regex("please compute my sentiment", ignore_case=TRUE))) {
# set user ID
user_id <- dm$events$message_create[i,]$sender_id
print(dm$events$message_create[i,]$sender_id)
# check if user has NOT already been accounted for (send reply after posted users)
if (!str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
regex("Done! Check my Feed!", ignore_case=TRUE))) {
print(dm$events$message_create[i,]$sender_id)
}
user_id
}
}
if (!str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
regex("Done! Check my Feed!", ignore_case=TRUE))) {
print(dm$events$message_create[i,]$sender_id)
}
!str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
regex("Done! Check my Feed!", ignore_case=TRUE))
q
quit()
get_timeline(dm$events$message_create[2,]$sender_id)
regex("Done! Check my Feed!", ignore_case=TRUE)
!str_detect(dm$events$message_create$message_data$text[dm$events$message_create$target$recipient_id == user_id],
Esc
"Esc"
get_timeline(dm$events$message_create[2,]$sender_id)
user_id
user_id
get_timeline(user_id, n=1)
# load lexicon
nrc_lexicon = read.csv('./data/lexicon/nrc_lexicon.csv')
rank
compute_analysis <- function(user_id) {
"Return a users Sentiment Analysis Plot"
setwd("~/Desktop/Quanta AI/Quanta_CS/MVP/Twitter Bot")
# load lexicon
nrc_lexicon = read.csv('./data/lexicon/nrc_lexicon.csv')
afinn_lexicon = read.csv('./data/lexicon/afinn_lexicon.csv')
bing_lexicon = read.csv('./data/lexicon/bing_lexicon.csv')
clean_tweets_text <- function(dataset) {
"Return: clean word tokens ranked by frequency of appearance"
dataset <- dataset %>% unnest_tokens(word, text) %>% select(word)          # clean & tokenize words
dataset <- dataset %>% anti_join(stop_words, by=c("word", "word"))         # remove stop words
dataset <- dataset %>% count(word, sort=TRUE)                              # count word appearences
dataset <- dataset[dataset$word != 'https',]                               # customly remove some unwanted terms
dataset <- dataset[is.na(as.numeric(dataset$word)),]                       # remove numbers
dataset <- dataset %>% mutate(word=reorder(word,n))                        # order (already done?)
return(dataset)
}
compute_bing_sentiment <- function(word_list, lexicon=bing_lexicon) {
"Compute the Corpus Sentiment for a given Lexicon"
word_list <- word_list %>% inner_join(lexicon, by=c('word','word')) %>% select(word, n, sentiment)
word_list$pole = ifelse(word_list$sentiment == 'positive', 1, -1)
word_list$score = word_list$pole * word_list$n
return(word_list)
}
# get & clean data
tweets <- get_timeline(n=10000, user=user_id)
clean_tweets <- clean_tweets_text(tweets)
# ________ ________ Compute Diversified Sentiment ________ ________
diversified_sentiment_analysis <- function(word_list, nrc_lexicon=nrc_lexicon) {
"Compute, plot & return the diversified sentiment"
diversed_sentiment <- unique(word_list %>% inner_join(nrc_lexicon) %>%
group_by(sentiment) %>% mutate(sum_n = sum(n)) %>% select(sum_n))
diversed_sentiment$proportion = diversed_sentiment$sum_n / sum(diversed_sentiment$sum_n)
diversed_sentiment$ratio = diversed_sentiment$proportion / max(diversed_sentiment$proportion)
rank <- data.frame(sentiment=c('positive','joy','surprise',"sadness",'disgust','negative',
'anger','fear','anticipation','trust'),
position=c(0,1,2,3,4,5,6,7,8,9),
sent=c(1,1,0,-1,-1,-1,-1,-1,0,1))
rank <- inner_join(diversed_sentiment, rank, by="sentiment")
rank <- rank[order(rank$position),]
return(rank)
}
# ____ Call Function ____
rank <- diversified_sentiment_analysis(clean_tweets, nrc_lexicon)
# ________ ________ Sentiment Rose Graph ________ ________
plt <- ggplot(rank, aes(x=reorder(sentiment, position), y=proportion, fill=factor(sent))) +
geom_bar(stat='identity', show.legend=F) +
coord_polar() + ggtitle(sprintf("Sentiment of %s's Tweets!", screen_name)) +
xlab("") + ylab("") +
theme(legend.position = "None",
axis.ticks.y = element_blank(),
axis.line.y = element_blank(),
axis.text.y = element_blank(),
plot.title = element_text(hjust = 0.5),
panel.background = element_rect(fill = "white"),
panel.grid.major = element_line(colour='#DCDCDC'),
panel.grid.minor  = element_line(colour='#DCDCDC')) +
scale_fill_manual(values=c(randomcoloR::randomColor(3)))
# Store Results --?
return(plt)
}
# ______________________________________________________ Compute Analysis ______________________________________________________
compute_analysis <- function(user_id) {
"Return a users Sentiment Analysis Plot"
setwd("~/Desktop/Quanta AI/Quanta_CS/MVP/Twitter Bot")
# load lexicon
nrc_lexicon = read.csv('./data/lexicon/nrc_lexicon.csv')
afinn_lexicon = read.csv('./data/lexicon/afinn_lexicon.csv')
bing_lexicon = read.csv('./data/lexicon/bing_lexicon.csv')
clean_tweets_text <- function(dataset) {
"Return: clean word tokens ranked by frequency of appearance"
dataset <- dataset %>% unnest_tokens(word, text) %>% select(word)          # clean & tokenize words
dataset <- dataset %>% anti_join(stop_words, by=c("word", "word"))         # remove stop words
dataset <- dataset %>% count(word, sort=TRUE)                              # count word appearences
dataset <- dataset[dataset$word != 'https',]                               # customly remove some unwanted terms
dataset <- dataset[is.na(as.numeric(dataset$word)),]                       # remove numbers
dataset <- dataset %>% mutate(word=reorder(word,n))                        # order (already done?)
return(dataset)
}
compute_bing_sentiment <- function(word_list, lexicon=bing_lexicon) {
"Compute the Corpus Sentiment for a given Lexicon"
word_list <- word_list %>% inner_join(lexicon, by=c('word','word')) %>% select(word, n, sentiment)
word_list$pole = ifelse(word_list$sentiment == 'positive', 1, -1)
word_list$score = word_list$pole * word_list$n
return(word_list)
}
# get & clean data
tweets <- get_timeline(n=10000, user=user_id)
clean_tweets <- clean_tweets_text(tweets)
# ________ ________ Compute Diversified Sentiment ________ ________
diversified_sentiment_analysis <- function(word_list, nrc_lexicon=nrc_lexicon) {
"Compute, plot & return the diversified sentiment"
diversed_sentiment <- unique(word_list %>% inner_join(nrc_lexicon) %>%
group_by(sentiment) %>% mutate(sum_n = sum(n)) %>% select(sum_n))
diversed_sentiment$proportion = diversed_sentiment$sum_n / sum(diversed_sentiment$sum_n)
diversed_sentiment$ratio = diversed_sentiment$proportion / max(diversed_sentiment$proportion)
rank <- data.frame(sentiment=c('positive','joy','surprise',"sadness",'disgust','negative',
'anger','fear','anticipation','trust'),
position=c(0,1,2,3,4,5,6,7,8,9),
sent=c(1,1,0,-1,-1,-1,-1,-1,0,1))
rank <- inner_join(diversed_sentiment, rank, by="sentiment")
rank <- rank[order(rank$position),]
return(rank)
}
# ____ Call Function ____
rank <- diversified_sentiment_analysis(clean_tweets, nrc_lexicon)
# ________ ________ Sentiment Rose Graph ________ ________
plt <- ggplot(rank, aes(x=reorder(sentiment, position), y=proportion, fill=factor(sent))) +
geom_bar(stat='identity', show.legend=F) +
coord_polar() + ggtitle(sprintf("Sentiment of %s's Tweets!", screen_name)) +
xlab("") + ylab("") +
theme(legend.position = "None",
axis.ticks.y = element_blank(),
axis.line.y = element_blank(),
axis.text.y = element_blank(),
plot.title = element_text(hjust = 0.5),
panel.background = element_rect(fill = "white"),
panel.grid.major = element_line(colour='#DCDCDC'),
panel.grid.minor  = element_line(colour='#DCDCDC')) +
scale_fill_manual(values=c(randomcoloR::randomColor(3)))
# Store Results --?
return(plt)
}
compute_analysis(user_id)
# post tweet
post_tweet(status='my first AI tweet #RebelBot', token=twitter_token)
