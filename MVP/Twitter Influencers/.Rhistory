print(d)
}
compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon)
sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon))
sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon)$score)
compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon)
sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon)['score'])
sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon)[['score']])
compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon)
sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon) %>% select(score))
sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon) %>% select(score))
rt <- sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon) %>% select(score))
rt
month(d) <- week(d) + 1
d <- as.Date("2019-01-01")
for (i in (1:12)) {
month(d) <- week(d) + 1
print(d)
}
d <- as.Date("2019-01-01")
for (i in (1:12)) {
week(d) <- week(d) + 1
print(d)
}
d <- as.Date("2019-01-01")
for (i in (1:52)) {
week(d) <- week(d) + 1
print(d)
}
d <- as.Date("2019-01-01")
for (i in (1:52)) {
print(d)
week(d) <- week(d) + 1
print(d)
}
since <- as.Date("2019-01-01")
since
since <- since + week(since) + 1
since <- as.Date("2019-01-01")
since + week(since) + 1
week(since) + 1
since <- as.Date("2019-01-01")
until <- since
week(until) <- week(since) + 1
since
until
rt
library(lubridate)
library(rtweet)
rt <- c()
since <- as.Date("2019-01-01")
for (i in (1:52)) {
until <- since
week(until) <- week(since) + 1
# compute
tweet <- search_tweets('richards_karin', since=since, until=until)
score <- sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon) %>% select(score))
rt <- c(rt, score)
# update dates
since <- until
}
rt
for (i in (1:5)) {
until <- since
week(until) <- week(since) + 1
print(since)
print(until)
# compute
tweet <- search_tweets('richards_karin', since=since, until=until)
score <- sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon) %>% select(score))
rt <- c(rt, score)
# update dates
since <- until
print(since)
}
rt <- c()
since <- as.Date("2019-01-01")
for (i in (1:5)) {
until <- since
week(until) <- week(since) + 1
print(since)
print(until)
# compute
tweet <- search_tweets('richards_karin', since=since, until=until)
score <- sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon) %>% select(score))
rt <- c(rt, score)
# update dates
since <- until
}
library(lubridate)
library(rtweet)
rt <- c()
since <- as.Date("2019-01-01")
for (i in (1:5)) {
until <- since
week(until) <- week(since) + 1
print(since)
print(until)
# compute
tweet <- search_tweets('richards_karin', since=since, until=until)
score <- sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon) %>% select(score))
rt <- c(rt, score)
# update dates
since <- until
}
compute_bing_sentiment <- function(word_list, lexicon, show_plots=FALSE, word_size=30, printt=F) {
"Compute the Corpus Sentiment for a given Lexicon"
# get bing sentiment
word_list <- word_list %>% inner_join(lexicon, by=c('word','word')) %>% select(word, n, sentiment)
# compute for visualization
word_list$pole = ifelse(word_list$sentiment == 'positive', 1, -1)
word_list$score = word_list$pole * word_list$n
# visualize
if (show_plots) {
net_sent <- ggplot(word_list, aes(word, score, fill=pole)) + geom_col() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
legend.position = 'none')
print(net_sent)
plt <- pie(x=c(mean(word_list$sentiment=="negative"),mean(word_list$sentiment=="positive")),
labels=c("negative",'positive'),
col=c("darkblue", "lightblue"))
print(plt)
# Visualize Most Common Positive vs Negative Words
plt <- word_list %>% group_by(sentiment) %>%
top_n(n=10, wt=n) %>% mutate(word=reorder(word,n)) %>%
ggplot(aes(reorder(word,n), n, fill=sentiment)) +
geom_col(show.legend=FALSE) +
facet_wrap(~sentiment, scales="free_y") +
labs(y = "Contribution to Sentiment",
x = NULL) +
coord_flip()
print(plt)
# generate wordcloud by sentiment colours
group = c(word_list$sentiment)
basecolours = c('darkgreen','darkred')
colourlist = basecolours[match(group,unique(group))]
plt <- wordcloud(words=word_list$word, freq=word_list$n,
colors=colourlist,
ordered.colors=T,
max.words=word_size)
print(plt)
# Structured sentiment word cloud
plt <- word_list %>% acast(word ~ sentiment, value.var="n", fill=0) %>%
comparison.cloud(colors=c("darkred",'darkgreen'),
max.words=word_size)
print(plt)
}
if (printt) {
print(paste("Proportion of POSITIVE sentiment words: ", mean(word_list$sentiment=="positive")))
print(paste("Proportion of NEGATIVE sentiment words: ", mean(word_list$sentiment=="negative")))
print(paste("Proportion of NEUTRAL sentiment words: ", mean(word_list$sentiment=="neutral")))
}
return(word_list)
}
for (i in (1:5)) {
until <- since
week(until) <- week(since) + 1
print(since)
print(until)
# compute
tweet <- search_tweets('richards_karin', since=since, until=until)
#  score <- sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon) %>% select(score))
rt <- c(rt, score)
# update dates
since <- until
}
library(lubridate)
library(rtweet)
rt <- c()
since <- as.Date("2019-01-01")
for (i in (1:5)) {
until <- since
week(until) <- week(since) + 1
# compute
tweet <- search_tweets('richards_karin', since=since, until=until)
print(tweet)
#  score <- sum(compute_bing_sentiment(clean_tweets_text(richards_karin), bing_lexicon) %>% select(score))
rt <- c(rt, score)
# update dates
since <- until
}
search_tweets('richards_karin', since="2019-01-01", until=("2019-01-20")
search_tweets('richards_karin', since="2019-01-01", until=("2019-01-20"))
library(lubridate)
library(rtweet)
search_tweets('richards_karin', since="2019-01-01", until=("2019-01-20"))
search_tweets('richards_karin', since="2019-01-01", until=("2019-10-20"))
search_tweets('richards_karin', since="2019-01-01", until=("2019-20-20"))
library(rtweet)
search_tweets('richards_karin', since="2019-01-01", until=("2019-20-20"))
search_tweets('richards_karin', since="2019-01-01", until=("2019-12-20"))
search_tweets('richards_karin', since="2019-01-01", until=("2019-12-20"))
search_tweets('richards_karin', since="2019-01-01", until=("2019-01-31"))
search_tweets('WarrenIngram', since="2019-01-01", until=("2019-01-31"))
search_tweets('WarrenIngram', since="2019-01-01", until=("2019-01-31"))
search_tweets('WarrenIngram', since="2019-01-01", until=("2019-01-31"))
search_tweets('WarrenIngram', since="2018-01-01", until=("2019-01-31"))
search_tweets('WarrenIngram', since="2018-01-01", until=("2019-01-31"))
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-31")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-10")
search_tweets('WarrenIngram', since="2018-01-01", until="2019-01-10")
library(twitteR)
searchTwitter('charlie sheen', since='2011-03-01', until='2011-03-02')
search_tweets('WarrenIngram', n=10 since="2018-01-01", until="2019-01-10")
search_tweets('WarrenIngram', n=10, since="2018-01-01", until="2019-01-10")
search_tweets('WarrenIngram', n=10, type="recent", since="2018-01-01", until="2019-01-10")
search_tweets('WarrenIngram', n=100, type="recent", since="2018-01-01", until="2019-01-10")
search_tweets('WarrenIngram', n=100000, type="recent", since="2018-01-01", until="2019-01-10")
jse_tweets_BIG
# download their timelines
jse_tweets_BIG <- get_timeline(users, n=5000)
library(rtweet)
# initial influencial users
users <- c('WarrenIngram', 'TradersCorner', 'paul_vestact', 'SimonPB', 'Richards_Karin',
'JP_Verster', 'Nerina_Visser','AdrianSaville', 'chrishartZA', 'davidshapiro61')
# download their timelines
jse_tweets_BIG <- get_timeline(users, n=5000)
head(jse_tweets_BIG)
jse_tweets_BIG %>% group_by(screen_name) %>% mutate(earlist_date = min(created_at))
# Filter for 2019
library(dplyr)
# Filter for 2019
library(dplyr)
library(tidytext)
# Filter for 2019
library(dplyr)
library(tidytext)
library(lubridate)
library(rtweet)
dates <- seq(from=as.Date("2019-01-01"), to=as.Date("2019-12-31"), by='week')
dates
for (w in (1:(length(dates)-1))) {
rt <- jse_tweets_BIG %>% filter(created_at>=dates[w], created_at<dates[w+1])
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
w =1
# store results
sent <- rbind(
sent,
data.frame(net_sentment, date[w], date[w+1])
)
}
compute_bing_sentiment <- function(word_list, lexicon=bing_lexicon, show_plots=FALSE, word_size=30, printt=F) {
"Compute the Corpus Sentiment for a given Lexicon"
# get bing sentiment
word_list <- word_list %>% inner_join(lexicon, by=c('word','word')) %>% select(word, n, sentiment)
# compute for visualization
word_list$pole = ifelse(word_list$sentiment == 'positive', 1, -1)
word_list$score = word_list$pole * word_list$n
# visualize
if (show_plots) {
net_sent <- ggplot(word_list, aes(word, score, fill=pole)) + geom_col() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
legend.position = 'none')
print(net_sent)
plt <- pie(x=c(mean(word_list$sentiment=="negative"),mean(word_list$sentiment=="positive")),
labels=c("negative",'positive'),
col=c("darkblue", "lightblue"))
print(plt)
# Visualize Most Common Positive vs Negative Words
plt <- word_list %>% group_by(sentiment) %>%
top_n(n=10, wt=n) %>% mutate(word=reorder(word,n)) %>%
ggplot(aes(reorder(word,n), n, fill=sentiment)) +
geom_col(show.legend=FALSE) +
facet_wrap(~sentiment, scales="free_y") +
labs(y = "Contribution to Sentiment",
x = NULL) +
coord_flip()
print(plt)
# generate wordcloud by sentiment colours
group = c(word_list$sentiment)
basecolours = c('darkgreen','darkred')
colourlist = basecolours[match(group,unique(group))]
plt <- wordcloud(words=word_list$word, freq=word_list$n,
colors=colourlist,
ordered.colors=T,
max.words=word_size)
print(plt)
# Structured sentiment word cloud
plt <- word_list %>% acast(word ~ sentiment, value.var="n", fill=0) %>%
comparison.cloud(colors=c("darkred",'darkgreen'),
max.words=word_size)
print(plt)
}
if (printt) {
print(paste("Proportion of POSITIVE sentiment words: ", mean(word_list$sentiment=="positive")))
print(paste("Proportion of NEGATIVE sentiment words: ", mean(word_list$sentiment=="negative")))
print(paste("Proportion of NEUTRAL sentiment words: ", mean(word_list$sentiment=="neutral")))
}
return(word_list)
}
for (w in 1:(52)) {
# for each week
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
sent <- c(sent, net_sentment)
}
# ____________________________ Compute Sentiment/week ____________________________
for (i in users) {
# for each user
rt <- weekly %>% filter(screen_name==i)
sent <- c()
for (w in 1:(52)) {
# for each week
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
sent <- c(sent, net_sentment)
}
# Store results
}
# ____________________________ Compute Sentiment/week ____________________________
for (i in users) {
# for each user
rt <- weekly %>% filter(screen_name==i)
sent <- c()
for (w in 1:(52)) {
# for each week
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
sent <- c(sent, net_sentment)
}
# Store results
}
# ____________________________ Compute Sentiment/week ____________________________
for (i in users) {
# for each user
rt <- weekly %>% filter(screen_name==i)
sent <- c()
# Store results
}
screen_name==i
# create weekly grouping
weekly <- jse_tweets_BIG %>% filter(created_at>="2019-01-01") %>% group_by(screen_name, week=week(created_at)) %>%
select(text, week, created_at, screen_name)
# ____________________________ Compute Sentiment/week ____________________________
for (i in users) {
# for each user
rt <- jse_tweets_BIG %>% filter(screen_name==i)
sent <- c()
for (w in 1:(52)) {
# for each week
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
sent <- c(sent, net_sentment)
}
# Store results
}
sent
sent <- c()
jse_tweets_BIG %>% filter(created_at>=dates[w], created_at<dates[w+1])
w
for (w in (1:(length(dates)-1))) {
print(w)
}
for (w in (1:(length(dates)-2))) {
print(w)
}
dates[1]
data.frame(net_sentment, date[w-1], date[w])
net_sentment
data.frame(net_sentiment=net_sentment, since=date[w-1], untildate[w])
c(net_sentiment=net_sentment, since=date[w-1], untildate[w])
c(net_sentiment=net_sentment, since=date[w-1], until=date[w])
data.frame(a=1, b='2', c=3)
date[w-1]
w
date[51]
date[5]
date
dates
dates[w]
dates[w+1]
data.frame(net_sentiment=net_sentment, since=dates[w-1], until=dates[w])
rbind(
data.frame(net_sentiment=net_sentment, since=dates[w-1], until=dates[w]),
data.frame(net_sentiment=net_sentment, since=dates[w-1], until=dates[w])
)
# store results
sent <- rbind(
sent,
data.frame(net_sentiment=net_sentment, since=dates[w-1], until=dates[w])
)
sent
# store results
sent <- rbind(
sent,
data.frame(net_sentiment=net_sentment, since=dates[w-1], until=dates[w])
)
sent
dates <- seq(from=as.Date("2019-01-01"), to=as.Date("2019-12-31"), by='week')
sent <- c()
for (w in (1:(length(dates)-2))) {
rt <- jse_tweets_BIG %>% filter(created_at>=dates[w], created_at<dates[w+1])
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
w =1
# store results
sent <- rbind(
sent,
data.frame(net_sentiment=net_sentment, since=dates[w-1], until=dates[w])
)
}
for (w in (1:(length(dates)-2))) {
rt <- jse_tweets_BIG %>% filter(created_at>=dates[w], created_at<dates[w+1])
}
for (w in (1:(length(dates)-2))) {
rt <- jse_tweets_BIG %>% filter(created_at>=dates[w], created_at<dates[w+1])
}
for (w in (1:(length(dates)-2))) {
rt <- jse_tweets_BIG %>% filter(created_at>=dates[w], created_at<dates[w+1])
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
}
for (w in (1:(length(dates)-2))) {
rt <- jse_tweets_BIG %>% filter(created_at>=dates[w], created_at<dates[w+1])
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
# store results
sent <- rbind(
sent,
data.frame(net_sentiment=net_sentment, since=dates[w-1], until=dates[w])
)
}
data.frame(net_sentiment=net_sentment, since=dates[w-1], until=dates[w])
for (w in (1:(length(dates)-2))) {
print(data.frame(net_sentiment=net_sentment, since=dates[w-1], until=dates[w]))
}
for (w in (1:(length(dates)-2))) {
print(w)
}
for (w in (1:(length(dates)-2))) {
rt <- jse_tweets_BIG %>% filter(created_at>=dates[w], created_at<dates[w+1])
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
# store results
sent <- rbind(
sent,
data.frame(net_sentiment=net_sentment, since=dates[w], until=dates[w+1])
)
}
sent
dates <- seq(from=as.Date("2019-01-01"), to=as.Date("2019-12-31"), by='week')
sent <- c()
for (w in (1:(length(dates)-2))) {
rt <- jse_tweets_BIG %>% filter(created_at>=dates[w], created_at<dates[w+1])
clean <- clean_tweets_text(rt)
net_sentment <- mean(compute_bing_sentiment(clean)[['score']])
# store results
sent <- rbind(
sent,
data.frame(net_sentiment=net_sentment, since=dates[w], until=dates[w+1])
)
}
head(sent)
ggplot(sent, aes(x=net_sentment, y=until)) + geom_line()
library(ggplot2)
ggplot(sent, aes(x=net_sentment, y=until)) + geom_line()
ggplot(sent, aes(x=until, y=net_sentment)) + geom_line()
sent
ggplot(jse_top40, aes(x=Date, y=Price)) + geom_line(col="darkblue") + ggtitle("JSE Top 40: Value")
head(sent)
ggplot(sent, aes(x=until, y=net_sentment)) + geom_line()
head(sent)
ggplot(sent, aes(x=until, y=net_sentment*1000)) + geom_line()
desc(sent$net_sentiment)
summary(sent$net_sentiment)
ggplot(data.frame(sent), aes(x=until, y=net_sentment)) + geom_line()
sent
ggplot(data.frame(sent), aes(x=since, y=net_sentment)) + geom_line()
ggplot(data.frame(sent), aes(x=since, y=net_sentment)) + geom_point()
mean(sent$net_sentiment)
library(ggplot2)
ggplot(data.frame(sent), aes(x=since, y=net_sentment)) + geom_point()
sent
data.frame(sent)
ggplot(data.frame(sent), aes(since, net_sentment)) + geom_point()
ggplot(data.frame(sent), aes(since, net_sentment)) + geom_line()
<- sent data.frame(sent)
sent <- sent data.frame(sent)
sent <- data.frame(sent)
mean(sent$net_sentiment)
library(ggplot2)
ggplot(data.frame(sent), aes(since, net_sentment)) + geom_line()
plot(x=sent$until, y=sent$net_sentiment)
plot(x=sent$until, y=sent$net_sentiment, "-")
plot(x=sent$until, y=sent$net_sentiment, "--")
ggplot(aes(x=sent$until, y=sent$net_sentiment)) + geom_line()
ggplot(sent, aes(x=sent$until, y=sent$net_sentiment)) + geom_line()
ggplot(sent, aes(x=sent$until, y=sent$net_sentiment)) + geom_line(col="orange")
jse_top40
jse_top40 %>% filter(Date >= "2019-01-01")
jse_top40 %>% filter(Date >= "2019-01-01") %>% select(Price)
ggplot(jse_top40, aes(x=Date, y=Change..)) + geom_line(col="lightblue") + ggtitle("JSE Top 40: Change")
ggplot(jse_top40 %>% filter(Date >= "2019-01-01"), aes(x=Date, y=Price)) + geom_line(col="lightblue") + ggtitle("JSE Top 40: Change")
ggplot(jse_top40 %>% filter(Date >= "2019-01-01"), aes(x=Date, y=Price)) + geom_line(col="lightblue") + ggtitle("JSE Top 40: Change")
ggplot(sent, aes(x=sent$until, y=sent$net_sentiment)) + geom_line(col="orange")
library(psycho)
install.packages((psycho))
library(psycho)
install.packages((psycho))
install.packages(('psycho'))
